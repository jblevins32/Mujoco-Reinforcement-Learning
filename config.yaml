# Note: must use 'import gymnasium as gym' in all files, not 'import gym'

# My simulation parameters
num_agents: 3
map_size: [100,50]
num_obstacles: 10
obstacle_radius_max: 15
obstacle_cost: 5.0
dynamics: "single_integrator"  # "unicycle" or "double_integrator"
max_episode_steps: 256
communication_range: 10.0
observation_range: 10.0
centralized: False
dt: 0.1
w_dist: 1
w_coll: 1
w_dir: 1
w_goal: 1
done_threshold: 5
seed_value: 42

# Training specific parameters
num_environments: 64
save_every: 100 # How many epochs to save the model
discount: 0.99
epsilon: 0.2
t_steps: 256
epochs: 1001
lr: .001
rl_alg: "PPO_CONT"

# Testing specific parameters
record_period: 1 # How many epochs to save the video
test_model_reward: "-43.51058" # Final reward of saved model (to differentiate them)
test_steps: 100

# Other parameters
space: "cont" # disc or cont depending on env
gym_model: "MRPP_Env" 
# Humanoid-v5 
# Pusher-v5
# HalfCheetah-v5 
# MountainCar-v0 
# CartPole-v1 
# Ant-v5 
# MRPP_Env

# Adversarial parameters
rl_alg_adv: "PPO_ADV"
adv_iter: 10